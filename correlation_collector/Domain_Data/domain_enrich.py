#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Function：
1. Read the domains_all.jsonl file generated by the collector (one domain record per line).
2. Merge the old domains_all_enriched.jsonl file (preserving existing VT/AbuseIPDB/OTX results).
3. During each execution, perform the following small-scale operations on the domains based on risk priority and daily limits:
  - VirusTotal domain reputation
  - AbuseIPDB IP reputation (for A records)
  - AlienVault OTX domain general info
4. Results are cumulatively written to domains_all_enriched.jsonl
  - Queries that have been queried will be cached (there is a last_checked field, so they won't be queried again every day).
"""

import json
import logging
import time
from datetime import datetime
from typing import Dict, Optional, Tuple, List

import requests

class Config:
    INPUT_DOMAINS_ALL = (
        "your_path"
    )

    OUTPUT_ENR = (
        "your_path"
    )

    VT_API_KEYS = [
        "<PUT_VT_KEY_1>",
        "<PUT_VT_KEY_2>",
    ]

    ABUSE_API_KEYS = [
        "<PUT_ABUSE_KEY_1>",
        "<PUT_ABUSE_KEY_2>",
    ]

    OTX_API_KEYS = [
        "<PUT_OTX_KEY_1>",
        "<PUT_OTX_KEY_2>",
    ]

    VT_MAX_PER_RUN = 80
    ABUSE_MAX_PER_RUN = 150
    OTX_MAX_PER_RUN = 150
    VT_MIN_DMS = 60
    ABUSE_MIN_DMS = 60
    OTX_MIN_DMS = 70

    VT_REFRESH_DAYS = 7
    ABUSE_REFRESH_DAYS = 7
    OTX_REFRESH_DAYS = 7

    VT_SLEEP_SECONDS = 15
    ABUSE_SLEEP_SECONDS = 5
    OTX_SLEEP_SECONDS = 10

    ABUSE_MAX_AGE_DAYS = 30

    LOG_LEVEL = logging.INFO


class KeyRotator:

    def __init__(self, keys: List[str]):
        self.keys = [k for k in keys if k and not k.startswith("<PUT_")]
        self.index = 0

    def get(self) -> Optional[str]:
        if not self.keys:
            return None
        key = self.keys[self.index]
        self.index = (self.index + 1) % len(self.keys)
        return key


VT_KEYS = KeyRotator(Config.VT_API_KEYS)
ABUSE_KEYS = KeyRotator(Config.ABUSE_API_KEYS)
OTX_KEYS = KeyRotator(Config.OTX_API_KEYS)

def init_logging():
    logging.basicConfig(
        level=Config.LOG_LEVEL,
        format="[%(asctime)s] [%(levelname)s] %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )


def load_jsonl_to_dict(path: str) -> Dict[str, dict]:
    """
    Read JSONL, assuming each line has a 'domain' field, and return `dict[domain] = record`.
    If the file does not exist, return an empty dict.
    """
    data: Dict[str, dict] = {}
    try:
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    rec = json.loads(line)
                except Exception as e:
                    logging.warning(f"JSON parse error in {path}: {e}")
                    continue
                dom = rec.get("domain")
                if not dom:
                    continue
                data[dom] = rec
        logging.info(f"Loaded {len(data)} records from {path}")
    except FileNotFoundError:
        logging.warning(f"{path} not found, skip load.")
    return data


def save_jsonl(path: str, data: Dict[str, dict]) -> None:
    """
    Write dict[domain] = record back to JSONL
    """
    logging.info(f"Saving {len(data)} records to {path}")
    with open(path, "w", encoding="utf-8") as f:
        for dom, rec in data.items():
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")


def parse_iso(ts: str) -> Optional[datetime]:
    try:
        return datetime.fromisoformat(ts)
    except Exception:
        return None

def now_utc() -> datetime:
    return datetime.utcnow()

def _get_dms(rec: dict) -> int:
    try:
        return int(rec.get("dms_score") or 0)
    except Exception:
        return 0

def _get_verdict_rank(rec: dict) -> int:
    verdict = (rec.get("verdict") or "unknown").lower()
    rank_map = {"malicious": 0, "suspicious": 1, "unknown": 2}
    return rank_map.get(verdict, 2)

def _get_url_count(rec: dict) -> int:
    features = rec.get("features") or {}
    try:
        return int(features.get("url_count") or 0)
    except Exception:
        return 0

def _priority_key(domain: str, rec: dict):
    """
    Sort by key: smaller numbers → higher priority.
    1. Verdict: malicious > suspicious > unknown
    2. Higher DMS (Data Management System) values ​​take precedence.
    3. Higher url_count values ​​take precedence.
    4. Alphabetical order is the last priority.
    """
    v_rank = _get_verdict_rank(rec)
    dms = _get_dms(rec)
    url_count = _get_url_count(rec)
    return (v_rank, -dms, -url_count, domain)


def _should_refresh(data: Optional[dict], last_key: str, refresh_days: int) -> bool:
    """
    Data: Contains last_key (ISO8601 string)
    No data or no last_key → True
    With last_key → True if the current date is >= refresh_days
    """
    if not data:
        return True
    last_ts = data.get(last_key)
    if not last_ts:
        return True
    dt = parse_iso(last_ts)
    if not dt:
        return True
    return (now_utc() - dt).days >= refresh_days


def vt_should_query(rec: dict) -> bool:
    if _get_dms(rec) < Config.VT_MIN_DMS:
        return False
    vt = rec.get("vt")
    return _should_refresh(vt, "last_checked", Config.VT_REFRESH_DAYS)


def abuse_should_query(rec: dict) -> bool:
    if _get_dms(rec) < Config.ABUSE_MIN_DMS:
        return False
    abuse = rec.get("abuseipdb")
    return _should_refresh(abuse, "last_checked", Config.ABUSE_REFRESH_DAYS)


def otx_should_query(rec: dict) -> bool:
    if _get_dms(rec) < Config.OTX_MIN_DMS:
        return False
    otx = rec.get("otx")
    return _should_refresh(otx, "last_checked", Config.OTX_REFRESH_DAYS)


def vt_query_domain(domain: str) -> Optional[dict]:
    api_key = VT_KEYS.get()
    if not api_key:
        logging.warning("VT_API_KEYS not set, skip VT query.")
        return None

    url = f"https://www.virustotal.com/api/v3/domains/{domain}"

    def do_request(key: str):
        headers = {"x-apikey": key}
        return requests.get(url, headers=headers, timeout=30)

    try:
        resp = do_request(api_key)
        if resp.status_code == 429:
            logging.warning("VT 429 rate limit, switching API key...")
            api_key2 = VT_KEYS.get()
            if api_key2:
                time.sleep(Config.VT_SLEEP_SECONDS)
                resp = do_request(api_key2)

        resp.raise_for_status()
        data = resp.json().get("data", {}).get("attributes", {})

        result = {
            "last_analysis_stats": data.get("last_analysis_stats", {}),
            "reputation": data.get("reputation"),
            "categories": list((data.get("categories") or {}).values()),
            "last_modification_date": data.get("last_modification_date"),
            "last_checked": now_utc().isoformat(),
        }
        return result
    except Exception as e:
        logging.warning(f"VT query failed for {domain}: {e}")
        return {
            "error": str(e),
            "last_checked": now_utc().isoformat(),
        }


def abuse_check_ip(ip: str) -> Optional[dict]:
    api_key = ABUSE_KEYS.get()
    if not api_key:
        logging.warning("ABUSE_API_KEYS not set, skip AbuseIPDB query.")
        return None

    url = "https://api.abuseipdb.com/api/v2/check"

    def do_request(key: str):
        headers = {
            "Key": key,
            "Accept": "application/json",
        }
        params = {
            "ipAddress": ip,
            "maxAgeInDays": Config.ABUSE_MAX_AGE_DAYS,
            "verbose": "yes",
        }
        return requests.get(url, headers=headers, params=params, timeout=20)

    try:
        resp = do_request(api_key)
        if resp.status_code == 429:
            logging.warning("AbuseIPDB 429 rate limit, switching key...")
            api_key2 = ABUSE_KEYS.get()
            if api_key2:
                time.sleep(Config.ABUSE_SLEEP_SECONDS)
                resp = do_request(api_key2)

        resp.raise_for_status()
        data = resp.json().get("data", {})

        result = {
            "abuseConfidenceScore": data.get("abuseConfidenceScore"),
            "totalReports": data.get("totalReports"),
            "lastReportedAt": data.get("lastReportedAt"),
            "isWhitelisted": data.get("isWhitelisted"),
            "usageType": data.get("usageType"),
            "isp": data.get("isp"),
            "domain": data.get("domain"),
            "countryCode": data.get("countryCode"),
            "hostnames": data.get("hostnames"),
            "last_checked": now_utc().isoformat(),
        }
        return result
    except Exception as e:
        logging.warning(f"AbuseIPDB query failed for {ip}: {e}")
        return {
            "error": str(e),
            "last_checked": now_utc().isoformat(),
        }


def otx_query_domain(domain: str) -> Optional[dict]:
    api_key = OTX_KEYS.get()
    if not api_key:
        logging.warning("OTX_API_KEYS not set, skip OTX query.")
        return None

    url = f"https://otx.alienvault.com/api/v1/indicators/domain/{domain}/general"

    def do_request(key: str):
        headers = {"X-OTX-API-KEY": key}
        return requests.get(url, headers=headers, timeout=30)

    try:
        resp = do_request(api_key)
        if resp.status_code == 429:
            logging.warning("OTX 429 rate limit, switching key...")
            api_key2 = OTX_KEYS.get()
            if api_key2:
                time.sleep(Config.OTX_SLEEP_SECONDS)
                resp = do_request(api_key2)

        resp.raise_for_status()
        data = resp.json()

        result = {
            "pulse_info": data.get("pulse_info", {}),
            "alexa": data.get("alexa", {}),
            "whois": data.get("whois", ""),
            "reputation": data.get("reputation"),
            "last_checked": now_utc().isoformat(),
        }
        return result
    except Exception as e:
        logging.warning(f"OTX query failed for {domain}: {e}")
        return {
            "error": str(e),
            "last_checked": now_utc().isoformat(),
        }


def enrich_with_vt_abuse_otx(all_domains: Dict[str, dict]) -> Dict[str, dict]:
    vt_count = 0
    abuse_count = 0
    otx_count = 0

    items: List[Tuple[str, dict]] = list(all_domains.items())
    items.sort(key=lambda kv: _priority_key(kv[0], kv[1]))

    for domain, rec in items:
        # --- VirusTotal ---
        if vt_count < Config.VT_MAX_PER_RUN and vt_should_query(rec):
            vt_data = vt_query_domain(domain)
            if vt_data is not None:
                rec["vt"] = vt_data
            vt_count += 1

        # --- AbuseIPDB ---
        # Capture A/NS records
        features = rec.get("features") or {}
        a_records = features.get("a_records") or []
        ns_records = features.get("ns_records") or []
        is_cloudflare = any("cloudflare.com" in ns for ns in ns_records)

        # If it's Cloudflare NS, skip AbuseIPDB (which is usually a CDN and not the actual source of the attack).
        if (
            abuse_count < Config.ABUSE_MAX_PER_RUN
            and a_records
            and abuse_should_query(rec)
            and not is_cloudflare
        ):
            abuse_data = rec.get("abuseipdb") or {"ips": {}}
            ips_dict = abuse_data.get("ips") or {}

            for ip in a_records:
                if abuse_count >= Config.ABUSE_MAX_PER_RUN:
                    break
                # If the IP already has records and has not expired, it will not be checked again (based on last_checked).
                ip_info = ips_dict.get(ip)
                if not _should_refresh(
                    ip_info, "last_checked", Config.ABUSE_REFRESH_DAYS
                ):
                    continue
                ip_info_new = abuse_check_ip(ip)
                if ip_info_new is not None:
                    ips_dict[ip] = ip_info_new
                    abuse_count += 1

            abuse_data["ips"] = ips_dict
            abuse_data["last_checked"] = now_utc().isoformat()
            rec["abuseipdb"] = abuse_data

        # --- OTX ---
        if otx_count < Config.OTX_MAX_PER_RUN and otx_should_query(rec):
            otx_data = otx_query_domain(domain)
            if otx_data is not None:
                rec["otx"] = otx_data
            otx_count += 1

    logging.info(
        f"API usage this run: VT={vt_count}, AbuseIPDB={abuse_count}, OTX={otx_count}"
    )
    return all_domains


def main():
    init_logging()
    logging.info("=== Domain enrichment (VT + AbuseIPDB + OTX) START ===")

    base = load_jsonl_to_dict(Config.INPUT_DOMAINS_ALL)

    if not base:
        logging.warning("No base domains loaded. Abort.")
        return

    enriched_old = load_jsonl_to_dict(Config.OUTPUT_ENR)
    if enriched_old:
        logging.info(f"Merging previous enriched data ({len(enriched_old)} records)...")
        for dom, rec_old in enriched_old.items():
            if dom in base:
                for key in ("vt", "abuseipdb", "otx"):
                    if key in rec_old:
                        base[dom][key] = rec_old[key]

    logging.info(f"Total domains to consider: {len(base)}")

    base = enrich_with_vt_abuse_otx(base)

    save_jsonl(Config.OUTPUT_ENR, base)
    logging.info(f"Saved enriched data to {Config.OUTPUT_ENR}")
    logging.info("=== Domain enrichment DONE ===")


if __name__ == "__main__":
    main()
